{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 用训练集训练模型，然后在测试集上面测试模型效果"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging as log\n",
    "from torch.optim import AdamW\n",
    "from back_tool import seed_everything,train_model,test_model,processing_data,MyDataset\n",
    "from models import MlpNeuralNet\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.实验前准备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1全局配置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "log.basicConfig(filename='log/log.txt', filemode='w', level=log.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "\n",
    "GLOB_CFG = { #训练的参数配置\n",
    "    'seed': 2,\n",
    "    'max_len': 100, #文本截断的最大长度\n",
    "    'epochs': 20,\n",
    "    'train_bs': 128, #batch_size，可根据自己的显存调整\n",
    "    'valid_bs': 256,\n",
    "    'test_bs': 256,\n",
    "    'lr': 8e-6, #学习率\n",
    "    'num_workers': 0,\n",
    "    'weight_decay': 2e-4, #权重衰减，防止过拟合\n",
    "    'device': 0,\n",
    "    'train_data': '模式识别数据集/train_data.pkl',\n",
    "    'test_data': None,\n",
    "    'val_data': '模式识别数据集/validation_data.pkl',\n",
    "    'log': log,\n",
    "    'train': True, #训练阶段为true 提交测试阶段为false\n",
    "    'processing_data': False,\n",
    "    'seq_length':300,\n",
    "    'sample_n': 100 # 抽取的样本条数，None表示抽取全部样本\n",
    "}\n",
    "\n",
    "seed_everything(GLOB_CFG['seed'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 导入数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "if GLOB_CFG['processing_data']:\n",
    "    processing_data('模式识别数据集', 'train', n=GLOB_CFG['sample_n'])\n",
    "    processing_data('模式识别数据集', 'validation', n=GLOB_CFG['sample_n'])\n",
    "train_df =  pd.read_pickle(GLOB_CFG['train_data'])\n",
    "test_df = None\n",
    "val_df = pd.read_pickle(GLOB_CFG['val_data'])\n",
    "data_set = MyDataset(train_df, test_df, val_df, GLOB_CFG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 实验一：多层感知机分类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 定义超参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import logging as mlp_log\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "mlp_log.basicConfig(filename='log/mlp_log.txt', filemode='w', level=log.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "\n",
    "MLP_CFG = GLOB_CFG.copy()\n",
    "MLP_CFG['log'] = mlp_log\n",
    "MLP_CFG['hidden_dim'] = 512\n",
    "MLP_CFG['feature_count'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 定义模型并训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s, acc=0.099, loss=10]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s, acc=0.0792, loss=10.7]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s, acc=0.109, loss=9.48]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s, acc=0.0891, loss=10.2]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s, acc=0.129, loss=8.96]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s, acc=0.0891, loss=9.64]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s, acc=0.139, loss=8.47]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s, acc=0.109, loss=9.13]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s, acc=0.149, loss=8.01]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s, acc=0.109, loss=8.65]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s, acc=0.168, loss=7.58]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.14it/s, acc=0.119, loss=8.21]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s, acc=0.178, loss=7.19]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s, acc=0.149, loss=7.81]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s, acc=0.188, loss=6.83]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.18it/s, acc=0.168, loss=7.45]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.23it/s, acc=0.218, loss=6.51]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s, acc=0.168, loss=7.11]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s, acc=0.228, loss=6.2]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s, acc=0.178, loss=6.78]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s, acc=0.238, loss=5.91]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.27it/s, acc=0.208, loss=6.46]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s, acc=0.238, loss=5.62]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s, acc=0.218, loss=6.15]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s, acc=0.248, loss=5.34]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s, acc=0.257, loss=5.85]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s, acc=0.257, loss=5.07]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s, acc=0.287, loss=5.57]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.05it/s, acc=0.277, loss=4.82]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s, acc=0.327, loss=5.31]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s, acc=0.347, loss=4.58]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s, acc=0.356, loss=5.07]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s, acc=0.366, loss=4.37]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s, acc=0.426, loss=4.86]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s, acc=0.396, loss=4.17]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.02it/s, acc=0.455, loss=4.66]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s, acc=0.475, loss=4]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s, acc=0.446, loss=4.48]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s, acc=0.485, loss=3.85]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s, acc=0.455, loss=4.32]\n",
      "100%|██████████| 20/20 [00:20<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MlpNeuralNet(MLP_CFG['seq_length']*MLP_CFG['feature_count'],\\\n",
    "    MLP_CFG['hidden_dim'],\\\n",
    "    data_set.get_label_num()).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=MLP_CFG['lr'], weight_decay=MLP_CFG['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "tk = tqdm(range(MLP_CFG['epochs']), total=MLP_CFG['epochs'], position=0, leave=True)\n",
    "for epoch in tk:\n",
    "        train_loss, train_acc = train_model(model,optimizer,  data_set,device,criterion, MLP_CFG)\n",
    "        val_loss, val_acc = test_model(model, data_set,criterion, device,MLP_CFG)\n",
    "        best_acc = 0\n",
    "        if val_acc > best_acc:\n",
    "            torch.save(model.state_dict(), './model_saved/{}_mlp_{}.pt'.format(epoch, round(val_acc, 4)))\n",
    "            best_acc = val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 实验二：LSTM分类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 定义超参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GLOB_CFG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/09/dw14yc6j0zb889_8lrfh11rc0000gp/T/ipykernel_60607/1181120357.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mMLP_CFG\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGLOB_CFG\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasicConfig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'log/mlp_log.txt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilemode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'w'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDEBUG\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mLOG_FORMAT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatefmt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDATE_FORMAT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mMLP_CFG\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'log'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mMLP_CFG\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hidden_dim'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mMLP_CFG\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'feature_count'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'GLOB_CFG' is not defined"
     ]
    }
   ],
   "source": [
    "import logging as lstm_log\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "lstm_log.basicConfig(filename='log/lstm_log.txt', filemode='w', level=log.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "\n",
    "CFG = GLOB_CFG.copy()\n",
    "CFG['log'] = lstm_log\n",
    "CFG['hidden_dim'] = 512\n",
    "CFG['feature_count'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 定义模型并训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model = MlpNeuralNet(CFG['seq_length']*CFG['feature_count'],\\\n",
    "    MLP_CFG['hidden_dim'],\\\n",
    "    data_set.get_label_num()).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "tk = tqdm(range(CFG['epochs']), total=CFG['epochs'], position=0, leave=True)\n",
    "for epoch in tk:\n",
    "        train_loss, train_acc = train_model(model,optimizer,  data_set,device,criterion, CFG)\n",
    "        val_loss, val_acc = test_model(model, data_set,criterion, device,CFG)\n",
    "        best_acc = 0\n",
    "        if val_acc > best_acc:\n",
    "            torch.save(model.state_dict(), './model_saved/{}_mlp_{}.pt'.format(epoch, round(val_acc, 4)))\n",
    "            best_acc = val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}